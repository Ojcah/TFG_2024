\babel@toc {spanish}{}\relax 
\contentsline {chapter}{\'{I}ndice de figuras}{\es@scroman {iii}}{chapter*.6}%
\contentsline {chapter}{\'{I}ndice de tablas}{\es@scroman {v}}{chapter*.7}%
\contentsline {chapter}{\nonumberline Lista de símbolos y abreviaciones}{\es@scroman {vi}}{chapter*.8}%
\contentsline {chapter}{\numberline {1}Introducción}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Aprendizaje automático en control}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Control con aprendizaje reforzado}{2}{section.1.2}%
\contentsline {section}{\numberline {1.3}Modelo controlador de planta de laboratorio PAMH con RL}{3}{section.1.3}%
\contentsline {section}{\numberline {1.4}Objetivos y estructura del documento}{4}{section.1.4}%
\contentsline {chapter}{\numberline {2}Marco teórico}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}Péndulo amortiguado de motor con hélice}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Modelo analítico del PAMH}{6}{subsection.2.1.1}%
\contentsline {section}{\numberline {2.2}Redes neuronales artificiales (RNA)}{7}{section.2.2}%
\contentsline {section}{\numberline {2.3}Aprendizaje reforzado}{8}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Conceptos base del RL}{9}{subsection.2.3.1}%
\contentsline {subsubsection}{Política}{9}{section*.19}%
\contentsline {subsubsection}{Recompensa}{9}{section*.20}%
\contentsline {subsubsection}{Procesos de decisión de Markov (MDP)}{10}{section*.21}%
\contentsline {subsubsection}{Paso}{10}{section*.22}%
\contentsline {subsubsection}{RL con redes neuronales}{10}{section*.23}%
\contentsline {subsubsection}{Etapas de exploración y explotación}{11}{section*.24}%
\contentsline {subsubsection}{Categorización del RL}{11}{section*.26}%
\contentsline {subsection}{\numberline {2.3.2}Deep Q-Network (DQN)}{12}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Optimización de política próxima (PPO)}{13}{subsection.2.3.3}%
\contentsline {section}{\numberline {2.4}Métricas de evaluación}{14}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Función de recompensa}{14}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Pérdida del modelo}{14}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Error de posición angular}{15}{subsection.2.4.3}%
\contentsline {chapter}{\numberline {3}Control de PAMH basado en aprendizaje reforzado}{16}{chapter.3}%
\contentsline {section}{\numberline {3.1}Selección de modelos de RL}{16}{section.3.1}%
\contentsline {section}{\numberline {3.2}Preparación de entornos virtuales}{17}{section.3.2}%
\contentsline {section}{\numberline {3.3}Parametrización de los modelos}{19}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Función de recompensa}{19}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Estructura de las RNA en DQN y PPO}{21}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}DQN}{22}{subsection.3.3.3}%
\contentsline {subsubsection}{Discretización}{22}{section*.30}%
\contentsline {subsubsection}{RNA para DQN}{22}{section*.31}%
\contentsline {subsubsection}{Plan de entrenamiento}{23}{section*.33}%
\contentsline {subsection}{\numberline {3.3.4}PPO}{23}{subsection.3.3.4}%
\contentsline {subsubsection}{RNA para PPO}{23}{section*.34}%
\contentsline {subsubsection}{Plan de entrenamiento}{24}{section*.36}%
\contentsline {subsection}{\numberline {3.3.5}Procesamiento y recopilación de datos}{25}{subsection.3.3.5}%
\contentsline {section}{\numberline {3.4}Evaluación de los modelos}{25}{section.3.4}%
\contentsline {chapter}{\numberline {4}Resultados y análisis}{26}{chapter.4}%
\contentsline {section}{\numberline {4.1}Implementación de métodos RL}{26}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Preparación del entorno virtual}{26}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Modelo DQN}{28}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}Modelo PPO}{28}{subsection.4.1.3}%
\contentsline {section}{\numberline {4.2}Evaluación del desempeño de los métodos RL}{30}{section.4.2}%
\contentsline {chapter}{\numberline {5}Conclusiones y recomendaciones}{33}{chapter.5}%
\contentsline {section}{\numberline {5.1}Conclusiones}{33}{section.5.1}%
\contentsline {section}{\numberline {5.2}Recomendaciones}{34}{section.5.2}%
\contentsline {chapter}{Bibliografía}{35}{chapter*.45}%
\contentsline {chapter}{\numberline {A}Algoritmo del método DQN}{37}{appendix.Alph1}%
\contentsline {chapter}{\numberline {B}Algoritmo del método PPO}{38}{appendix.Alph2}%
